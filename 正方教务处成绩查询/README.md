#项目分析
[TOC]
----

**项目内容：**
用Python写的正方教务系统的网络爬虫。

**程序功能：**
将教务处的历年成绩打包成EXCEL存储到本地。

**项目收获：**
1. 了解cookie的相关操作
2. 代码实现网页跳转
3. 以post形式提交数据
4. 爬取网页中table的数据（这里使用第三方库-beautifulSoup解决，使用正则表达式太麻烦）
5. python将数据存入EXCEL表
6. 如何安装和使用第三方库
7. 登陆验证码解决（这里采用将图片下载下来后在控制台输入）

**代码分析：**
+ 24：

    HTTP Referer是header的一部分，当浏览器向web服务器发送请求的时候，一般会带上Referer，告诉服务器我是从哪个页面链接过来的，服务 器 籍此可以获得一些信息用于处理。比如从我主页上链接到一个朋友那里，他的服务器就能够从HTTP Referer中统计出每天有多少用户点击我主页上的链接访问他的网站。
    如果不加上Referer就会出现下面错误
![此处输入图片的描述][1]
  [1]: http://pic.w2bc.com/upload/201505/12/201505120928535613.jpg

+ 81：

    如果仅是想要解析HTML文档,只要用文档创建 BeautifulSoup 对象就可以了.Beautiful Soup会自动选择一个解析器来解析文档.但是还可以通过参数指定使用那种解析器来解析当前文档.
    
    BeautifulSoup 第一个参数应该是要被解析的文档字符串或是文件句柄,第二个参数用来标识怎样解析文档.如果第二个参数为空,那么Beautiful Soup根据当前系统安装的库自动选择解析器,解析器的优先数序: lxml, html5lib, Python标准库.在下面两种条件下解析器优先顺序会变化:
    
    要解析的文档是什么类型: 目前支持, “html”, “xml”, 和 “html5”
    指定使用哪种解析器: 目前支持, “lxml”, “html5lib”, 和 “html.parser”

 